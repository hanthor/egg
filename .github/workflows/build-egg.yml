name: Build Bluefin Egg

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  IMAGE_NAME: egg
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  BST2_IMAGE: registry.gitlab.com/freedesktop-sdk/infrastructure/freedesktop-sdk-docker-images/bst2:f89b4aef847ef040b345acceda15a850219eb8f1
  R2_BUCKET: bst-cache

# On PRs: group by branch so new pushes cancel stale runs.
# On main: group by SHA so every push gets its own non-cancellable run.
# (GitHub cancels even pending/queued runs in the same group regardless of
#  cancel-in-progress when a newer run arrives, so main needs unique groups.)
concurrency:
  group: ${{ github.workflow }}-${{ github.event_name == 'pull_request' && github.ref || github.sha }}
  cancel-in-progress: ${{ github.event_name == 'pull_request' }}

jobs:
  build:
    runs-on: ubuntu-24.04
    permissions:
      contents: read
      packages: write
    steps:
      # ── Host-level setup ──────────────────────────────────────────────
      # These steps MUST run on the host, not inside the bst2 container.
      # We cannot use `container:` at job level because
      # ublue-os/remove-unwanted-software needs host filesystem access.

      - name: Free disk space
        uses: ublue-os/remove-unwanted-software@695eb75bc387dbcd9685a8e72d23439d8686cba6

      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Pull BuildStream container image
        run: podman pull "$BST2_IMAGE"

      - name: Cache BuildStream sources
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: ~/.cache/buildstream/sources
          key: bst-sources-${{ hashFiles('elements/**/*.bst', 'project.conf') }}
          restore-keys: |
            bst-sources-

      - name: Prepare BuildStream cache directory
        run: |
          mkdir -p "$HOME/.cache/buildstream/sources"
          mkdir -p "$HOME/.cache/buildstream/cas"
          mkdir -p "$HOME/.cache/buildstream/artifacts"
          mkdir -p "$HOME/.cache/buildstream/source_protos"

      # ── Restore cache from R2 ─────────────────────────────────────────
      # Use rclone to sync BuildStream's CAS and artifact metadata from
      # Cloudflare R2. rclone only transfers files that differ (by size
      # and checksum), making this incremental. The CAS is content-
      # addressed so files never change — only new blobs are downloaded.

      - name: Install rclone
        run: |
          curl -fsSL https://rclone.org/install.sh | sudo bash
          rclone version

      - name: Restore BuildStream cache from R2
        env:
          R2_ACCESS_KEY: ${{ secrets.R2_ACCESS_KEY }}
          R2_SECRET_KEY: ${{ secrets.R2_SECRET_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
        run: |
          if [ -z "${R2_ACCESS_KEY}" ]; then
            echo "R2 secrets not configured, skipping cache restore"
            exit 0
          fi

          # Configure rclone for Cloudflare R2 (S3-compatible)
          mkdir -p ~/.config/rclone
          cat > ~/.config/rclone/rclone.conf <<EOF
          [r2]
          type = s3
          provider = Cloudflare
          access_key_id = $R2_ACCESS_KEY
          secret_access_key = $R2_SECRET_KEY
          endpoint = $R2_ENDPOINT
          no_check_bucket = true
          EOF
          # Strip leading whitespace from config (heredoc is indented in YAML)
          sed -i 's/^[[:space:]]*//' ~/.config/rclone/rclone.conf

          BST_CACHE="$HOME/.cache/buildstream"

          echo "=== Restoring CAS objects from R2 ==="
          rclone sync "r2:${R2_BUCKET}/cas/" "${BST_CACHE}/cas/" \
            --transfers=32 \
            --checkers=64 \
            --fast-list \
            --stats=10s \
            --stats-one-line \
            -v || echo "::warning::CAS restore from R2 failed (non-fatal)"

          echo "=== Restoring artifact refs from R2 ==="
          rclone sync "r2:${R2_BUCKET}/artifacts/" "${BST_CACHE}/artifacts/" \
            --transfers=16 \
            --checkers=32 \
            --fast-list \
            -v || echo "::warning::Artifact refs restore from R2 failed (non-fatal)"

          echo "=== Restoring source protos from R2 ==="
          rclone sync "r2:${R2_BUCKET}/source_protos/" "${BST_CACHE}/source_protos/" \
            --transfers=16 \
            --checkers=32 \
            --fast-list \
            -v || echo "::warning::Source protos restore from R2 failed (non-fatal)"

          echo "=== Cache restore summary ==="
          du -sh "${BST_CACHE}/cas" "${BST_CACHE}/artifacts" \
                 "${BST_CACHE}/source_protos" "${BST_CACHE}/sources" 2>/dev/null || true
          df -h /

      - name: Disk space before build
        run: df -h /

      # ── Generate CI-specific BuildStream config ───────────────────────
      # Tuned per gnome-build-meta CI patterns:
      # - on-error: continue  -> find ALL failures, don't stop at first
      # - fetchers: 12        -> parallel downloads from upstream caches
      # - builders: 1         -> GHA has 4 vCPUs; single builder avoids OOM
      # - retry-failed: True  -> auto-retry flaky builds
      # - error-lines: 80     -> generous error context in logs
      # - cache-buildtrees: never -> save disk (we only need final artifacts)
      #
      # No remote artifact server is configured. BuildStream uses only:
      # 1. Local disk cache (restored from R2 above)
      # 2. Upstream GNOME caches defined in project.conf (read-only)
      # After the build, rclone syncs everything back to R2.

      - name: Generate BuildStream CI config
        run: |
          mkdir -p logs
          cat > buildstream-ci.conf <<'BSTCONF'
          scheduler:
            on-error: continue
            fetchers: 12
            builders: 1
            network-retries: 3

          logging:
            message-format: '[%{wallclock}][%{elapsed}][%{key}][%{element}] %{action} %{message}'
            error-lines: 80

          build:
            max-jobs: 0
            retry-failed: True

          cache:
            cache-buildtrees: never
          BSTCONF

          echo "=== BuildStream CI config ==="
          cat buildstream-ci.conf

      # ── BuildStream build ─────────────────────────────────────────────
      # Runs inside the bst2 container with:
      # - --privileged: required for bubblewrap sandboxing
      # - --device /dev/fuse: required for buildbox-fuse (ext4 lacks reflinks)
      # - ulimit -n 1048576: buildbox-casd needs many file descriptors
      # - --no-interactive: prevent blocking on prompts in CI

      - name: Build OCI image with BuildStream
        run: |
          podman run --rm \
            --privileged \
            --device /dev/fuse \
            --network=host \
            -v "${{ github.workspace }}:/src:rw" \
            -v "$HOME/.cache/buildstream:/root/.cache/buildstream:rw" \
            -w /src \
            "$BST2_IMAGE" \
            bash -c '
              ulimit -n 1048576 || true
              bst --no-interactive \
                  --colors \
                  --config /src/buildstream-ci.conf \
                  --log-file /src/logs/build.log \
                  build \
                  oci/bluefin.bst
            '
        timeout-minutes: 120

      # ── Sync cache to R2 ──────────────────────────────────────────────
      # Always runs (even on build failure) so that partial progress is
      # preserved. Every run incrementally grows the R2 cache.
      #
      # rclone sync is incremental: CAS blobs are content-addressed and
      # immutable, so only newly-created files are uploaded. Artifact
      # refs and source protos are small metadata files.
      #
      # We use --ignore-existing for the CAS directory because CAS blobs
      # are immutable — if a file with the same name exists in R2 it has
      # the same content (content-addressed by SHA256). This skips the
      # checksum comparison and is much faster for large caches.

      - name: Sync BuildStream cache to R2
        if: always()
        continue-on-error: true
        env:
          R2_ACCESS_KEY: ${{ secrets.R2_ACCESS_KEY }}
          R2_SECRET_KEY: ${{ secrets.R2_SECRET_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
        run: |
          if [ -z "${R2_ACCESS_KEY}" ]; then
            echo "R2 secrets not configured, skipping cache sync"
            exit 0
          fi

          BST_CACHE="$HOME/.cache/buildstream"

          echo "=== Local cache sizes ==="
          du -sh "${BST_CACHE}/cas" "${BST_CACHE}/artifacts" \
                 "${BST_CACHE}/source_protos" "${BST_CACHE}/sources" 2>/dev/null || true

          echo "=== Syncing CAS objects to R2 ==="
          # --copy (not sync) ensures we never delete from R2 — only add.
          # --ignore-existing skips blobs already in R2 (CAS is immutable).
          rclone copy "${BST_CACHE}/cas/" "r2:${R2_BUCKET}/cas/" \
            --transfers=32 \
            --checkers=64 \
            --s3-upload-concurrency=4 \
            --s3-chunk-size=16M \
            --ignore-existing \
            --fast-list \
            --stats=10s \
            --stats-one-line \
            -v || echo "::warning::CAS sync to R2 failed"

          echo "=== Syncing artifact refs to R2 ==="
          # Artifact refs can be updated, so use sync (not copy).
          rclone sync "${BST_CACHE}/artifacts/" "r2:${R2_BUCKET}/artifacts/" \
            --transfers=16 \
            --checkers=32 \
            --fast-list \
            -v || echo "::warning::Artifact refs sync to R2 failed"

          echo "=== Syncing source protos to R2 ==="
          rclone sync "${BST_CACHE}/source_protos/" "r2:${R2_BUCKET}/source_protos/" \
            --transfers=16 \
            --checkers=32 \
            --fast-list \
            -v || echo "::warning::Source protos sync to R2 failed"

          echo "=== R2 sync complete ==="

      - name: Disk space after build
        if: always()
        run: df -h /

      # ── Export OCI image ──────────────────────────────────────────────
      # Stream the OCI tar from BuildStream directly into podman on the
      # host. This avoids writing an intermediate tar file to disk.
      # Pattern: bst artifact checkout --tar - | podman load

      - name: Export OCI image from BuildStream
        id: export
        run: |
          LOADED=$(podman run --rm \
            --privileged \
            --device /dev/fuse \
            -v "${{ github.workspace }}:/src:rw" \
            -v "$HOME/.cache/buildstream:/root/.cache/buildstream:rw" \
            -w /src \
            "$BST2_IMAGE" \
            bash -c '
              ulimit -n 1048576 || true
              bst --no-interactive \
                  --config /src/buildstream-ci.conf \
                  artifact checkout --tar - oci/bluefin.bst
            ' | podman load)
          # podman load prints "Loaded image: <name>:<tag>" or "Loaded image(s): <id>"
          IMAGE_REF=$(echo "$LOADED" | grep -oP '(?<=Loaded image: ).*' || \
                      echo "$LOADED" | grep -oP '(?<=Loaded image\(s\): ).*')
          echo "image_ref=$IMAGE_REF" >> "$GITHUB_OUTPUT"
          echo "Loaded: $IMAGE_REF"

      - name: Verify image loaded
        run: podman images

      # ── Validation ────────────────────────────────────────────────────

      - name: Validate with bootc container lint
        run: |
          podman run --rm --privileged \
            -v /var/lib/containers:/var/lib/containers \
            "${{ steps.export.outputs.image_ref }}" \
            bootc container lint

      # ── Upload build logs ─────────────────────────────────────────────
      # Always upload, even on failure, so build failures can be diagnosed.

      - name: Upload build logs
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: buildstream-logs
          path: logs/
          retention-days: 7
          if-no-files-found: ignore

      # ── Publish to GHCR (main branch only) ───────────────────────────

      - name: Login to GHCR
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          echo "${{ secrets.GITHUB_TOKEN }}" | \
            podman login ghcr.io --username ${{ github.actor }} --password-stdin

      - name: Tag image for GHCR
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          podman tag "${{ steps.export.outputs.image_ref }}" \
            "${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:latest" \
            "${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}"

      - name: Push to GHCR
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          podman push --retry 3 "${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
          podman push --retry 3 "${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}"
